{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2a2c2b",
   "metadata": {},
   "source": [
    "# 1\n",
    "The key factor that distinguishes the ideas that whether it can be statistically tested or not is measurability. An idea must invovle variables that can be observed, quanitified, and analyzed using data.\n",
    "\n",
    "A good null hypothesis should be specific, testable, and framed in a way that represents no effect, no relationship, or no difference. It must allow for clear statistical testing. \n",
    "\n",
    "In the context of hypothesis testing, the null hypothesis(Hâ‚€)is the one to be tested, and the alternative hypothesis(Hâ‚) is everything else. Furthermore, the null hypothesis states that there's no effect or difference. The alternative hypothesis proposes that there's an effect or difference. The goal of hypothesis testing is to gather evidence through data to determine if we can reject the null hypothesis to accept the alternative hypothesis. In other words, our ultimate goal is to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd9c7e",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53386b60",
   "metadata": {},
   "source": [
    "## When we conduct hypothesis testing, our goal is to make conclusions about the entire population, not just the sample we collected.\n",
    "\n",
    "- ð‘¥ð‘–'s: These are the individual data points or values in the sample(i.e. individual scores)\n",
    "- ð‘¥Ì„: The sample mean, which is the average of all ð‘¥áµ¢ values in the sample(i.e. the average score of participants)\n",
    "- ðœ‡: This represents the true mean of the population, which we usually don't know(i.e. the average score if we could measure everyone in the population)\n",
    "- ðœ‡â‚€: This is the mean stated in the null hypothesis(i.e. the claim that \"the population average is 70\")\n",
    "\n",
    "### Overall, when the test is done, we are trying to see if the sample mean (ð‘¥Ì„) provides enough evidence to make a conclusion about the population mean(ðœ‡) compared to the hypothesis mean(ðœ‡â‚€)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844a1cd",
   "metadata": {},
   "source": [
    "# ChatGPT Summary\n",
    "**Summary of Interaction with ChatGPT:**\n",
    "\n",
    "I consulted ChatGPT to gain a better understanding of hypothesis testing and the interpretation of statistical concepts from a pre-lecture video.\n",
    "\n",
    "1. **Key Factors for Statistical Testing:** ChatGPT explained that the key factor distinguishing ideas that can be statistically tested is *measurability*. Hypotheses must involve variables that can be observed and quantified using data.\n",
    "\n",
    "2. **Criteria for a Good Null Hypothesis:** A good null hypothesis is *specific*, *testable*, and represents no effect or difference. It should allow for clear statistical testing.\n",
    "\n",
    "3. **Difference Between Null and Alternative Hypotheses:** The *null hypothesis (Hâ‚€)* states there is no effect or difference (e.g., \"the treatment has no impact\"), while the *alternative hypothesis (Hâ‚)* suggests that there is an effect or difference (e.g., \"the treatment improves outcomes\"). The goal of hypothesis testing is to evaluate whether the sample data provides enough evidence to reject Hâ‚€ in favor of Hâ‚.\n",
    "\n",
    "4. **Distinction Between Population Parameters and Sample Statistics:** ChatGPT clarified that hypothesis testing aims to draw conclusions about the population mean (Î¼), not just the sample mean (xÌ„). The sample mean (xÌ„) represents the average of data points in the sample (ð‘¥áµ¢), but the goal is to infer something about the true mean of the entire population (Î¼). The null hypothesis (Î¼â‚€) is tested to see if it can be rejected in light of the sample data.\n",
    "\n",
    "This interaction helped clarify the concepts for me and provided a concise explanation of the key points related to hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a64e99",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48106fc0",
   "metadata": {},
   "source": [
    "In hypothesis testing, we calculate the p-value by imagining a world where the null hypothesis(Hâ‚€) is true. This means we asumme that there is no effect or difference(i.e. no impact), and then calculate how likely it would be to observe the data we have, or something more extreme, under this assumption.\n",
    "\n",
    "The reason we do this is because the sampling distribution of the test statistic(i.e. the mean or difference in means) under Hâ‚€ represents the range of outcomes we expect if the null hypothesis is correct. By comparing the actual test statistic to this distribution, we can see whether our observed data is typical or unusual. If the data is very unlikely under Hâ‚€(i.e. the p-value is small), we have evidence to reject the null hypothesis and consider the alternative hypothesis. \n",
    "\n",
    "In other words, the p-value helps us quantify how compatible our data is with a word where the null hypothesis is true. If the data is too extreme, it suggests the null hypothesis may not hold. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3de151",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30145df",
   "metadata": {},
   "source": [
    "A smaller p-value makes the null hypothesis look more \"ridiculous\" because it tells us that, if the null hypothesis(Hâ‚€) were true, the likelihood of observing data as extreme as what we actually observed is very low.\n",
    "\n",
    "- The p-value: represents the probability of getting a test statistic as extreme as the one observed, assuming the null hypothesis is true\n",
    "\n",
    "- The test statistic: calculated based on the observed data, and compare this statistic to the sampling distribution of the test statistic under the null hypothesis\n",
    "\n",
    "- If the p-value is very small(say, close to 0), it means that the observed result is far out in the tails of ths sampling distribution. In other words, it's a highly unusual result in a world where the null hypothesis is true. \n",
    "\n",
    "So, when the p-value is tiny, it suggests that the actual data is so unlikely under Hâ‚€ that it becomes unreasonable to believe the null hypothesis. This makes Hâ‚€ seem increasinlgy implausible, or \"ridiculous,\" because it would mean something very unlikely happened purely by chance. Hence, we reject Hâ‚€ and consider the alternative hypothesis(Hâ‚) to be more likely. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145833e1",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8d1d03",
   "metadata": {},
   "source": [
    "Assume the null hypothesis Hâ‚€, which states that people have no left or right head tilt tendencies when kissing(i.e., a 50/50 chance).\n",
    "\n",
    "## Step 1: Define the problem in terms of statistical concepts\n",
    "- Observed data: 80 out of 124 couples (64.5%) tilted their heads to the right\n",
    "- Null hypothesis(Hâ‚€): There's no preference for head-titlting direction (50% of people tilt to the right)\n",
    "- Sample proportion(pÌ‚): The obeserved proportion of head tilts to the right is 64.5% (0.645)\n",
    "- Population proportion under Hâ‚€(pâ‚€): The assumed population proportion is 50%(0.5) since we assume no preference\n",
    "\n",
    "## Step 2: Simulate a world where the null hypothesis is true\n",
    "To simulate this, we can perform a series of coin flips, treating \"heads\" as a tilt to the right and \"tails\" as a tilt to the left, with each flip having a 50% probability. We want to simulate the proportion of right tilts under this null model and see how extreme the observed result(64.5% right tilts) is. \n",
    "1. Generate simulated outcomes. In each simulation, flip a \"coin\" 124 times(for each couple) with a 50% chance of tilting right. Calculate the proportion of simulated tilts to the right. \n",
    "2. Repeat this process many times(e.g., 10,000 simulations) to generate a distribution of simulated proportions under the assumption that Hâ‚€ is true.\n",
    "\n",
    "## Step 3: Calculate the p-value\n",
    "The p-value is the proportion of simulations where the simulated proportion of couples tilting to the right is greater than or equal to the observed 64.5%(0.645). This tells us how likely it is to observed a result as extreme or more extreme than what we observed, assuming the null hypothesis is true. \n",
    "\n",
    "## Step 4: Evaluate the strength of evidence against Hâ‚€\n",
    "Use the following table to interpret the p-value:\n",
    "\n",
    "- ð‘>0.1: No evidence against the null hypothesis\n",
    "- 0.1â‰¥ð‘>0.05: Weak evidence against the null hypothesis\n",
    "- 0.05â‰¥ð‘>0.01: Moderate evidence against the null hypothesis\n",
    "- 0.01â‰¥ð‘>0.001: Strong evidence against the null hypothesis\n",
    "- 0.001â‰¥ð‘: Very strong evidence against the null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fca5a5",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed9a741",
   "metadata": {},
   "source": [
    "A smaller p-value doesn't definitively prove that the null hypothesis is false. Instead, it tells us how likely or unlikely the observed data is under the assumption that the null hypothesis is true. The p-value measures the strength of evidence against the null hypothesis but does not offer absolute proof. \n",
    "\n",
    "Fido from the video:\n",
    "- A p-value cannot definitively prove innocence(that Fido is not guilty) because failing to reject the null hypothesis(i.e., finding a high p-value) simply means there isn't strong enough evidence to reject it- it doesn't prove the null hypothesis is true. \n",
    "- A p-value also cannot definitively prove guilt(that Fido is guilty) because even with a very low p-value, all we can say is that the data is highly unlikley under the null hypothesis. There's always a small chance the observed result occurred by random variation. \n",
    "\n",
    "No p-value, no matter how low or high, can offer definite proof in either direction. Hypothesis testing works on probabilities, not absolute certainty. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f84a08",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7890907",
   "metadata": {},
   "source": [
    "## Key Points in the Code\n",
    "\n",
    "### 1. Random Generation:\n",
    "- random_difference_sign : Generates random changes(improvement or declines) in health scores under the assumption of no average effect(the null hypothesis)\n",
    "- random_improvement.mean() is calculated to get the proportion of positive health score changes under the null hypothesis(random improvement)\n",
    "\n",
    "### 2. Simulation:\n",
    "- The loop simulates 10,000 proportions assuming the null hypothesis is true. Each simulation randomly assigns health score changes to be positive or negative\n",
    "- The observed statistic is the actual proportion of positive health score changes in the real data\n",
    "\n",
    "### 3. Two-Tailed p-value:\n",
    "- The p-value is calculated as the proportion of simulated statistics that are \"as or more extreme\" than the observed statistic\n",
    "- In a two-tailed test, \"extreme\" means any statistic that is as far or farther from the hypothesized parameter(0.5) as the observed statistic, in either direction(both positive and negative extremes)\n",
    "\n",
    "### Changing to a One-Tailed Test\n",
    "We are only interested in one direction. For example, if we hypothesize that the health score changes are greater than 0 (positive health changes), we only look at the right side(upper tail) of the distribution.\n",
    "\n",
    "### Adjustments in the code\n",
    "1. Remove the symmetric test:\n",
    "- We only check for values greater than the observed statistic instead of checking for values as extreme on both sides\n",
    "2. Update Code for One-Tailed Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line for a one-tailed test (right-sided):\n",
    "SimStats_as_or_more_extreme_than_ObsStat = simulated_statistics >= observed_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc8b165",
   "metadata": {},
   "source": [
    "This change tells the code to only count the simulated statistics that are greater than or equal to the observed statistic, focusing on one side of the distribution(right-tailed).\n",
    "\n",
    "3. Update p-value Calculation:\n",
    "- Recalculate the p-value using this new one-tailed approach. The rest of the code remains the same.\n",
    "\n",
    "4. Expected p-value:\n",
    "- Since the two-tailed test includes both tails, the one-tailed test generally results in a smaller p-value because we are only considering one side. This means fewer simulated values will be \"as extreme\" as the observed statistic, reducing the p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0793d62c",
   "metadata": {},
   "source": [
    "# ChatGPT Summary\n",
    "\n",
    "### Summary of Interaction for Assignment\n",
    "\n",
    "We worked together to adjust the code from \"Demo II of Week 5 TUT\" in order to compute a p-value for a one-sided (one-tailed) hypothesis test rather than the two-sided (two-tailed) version provided. Below are the key points discussed:\n",
    "\n",
    "1. **Initial Two-Sided Test Code**:\n",
    "    - The original code simulates 10,000 random improvements in health scores under the null hypothesis (that the vaccine has no effect). The code checks for \"as or more extreme\" results, where \"extreme\" means being far from the hypothesized parameter (0.5) in both directions (two-tailed).\n",
    "    - The p-value is calculated based on how many of the simulated statistics are as extreme or more extreme than the observed statistic.\n",
    "\n",
    "2. **Changes for One-Sided Test**:\n",
    "    - To convert the test from two-tailed to one-tailed, we adjusted the part of the code that checks for extreme values. Instead of checking both sides, we only checked one side (right tail), focusing on whether the simulated statistics were greater than the observed statistic.\n",
    "    - The line that was modified:\n",
    "      ```python\n",
    "      SimStats_as_or_more_extreme_than_ObsStat = simulated_statistics >= observed_statistic\n",
    "      ```\n",
    "    - This change restricts the p-value calculation to one tail of the sampling distribution, representing a one-sided test.\n",
    "\n",
    "3. **Expected Outcome**:\n",
    "    - A one-tailed test generally leads to a smaller p-value compared to a two-tailed test because we are only considering one direction of extremity. This can lead to stronger evidence against the null hypothesis if the observed statistic aligns with the direction we are testing for.\n",
    "\n",
    "4. **Conclusion**:\n",
    "    - By narrowing the focus of the test to one side, we refined the hypothesis test to specifically test if health scores improved, rather than testing for any change (improvement or decline).\n",
    "    - The resulting p-value should be smaller because fewer simulated statistics will be considered \"as or more extreme\" in a one-tailed test.\n",
    "\n",
    "This interaction helped me understand how to adapt a two-sided test to a one-sided test and interpret the impact of the change on the p-value calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0643c6b3",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb0d0f",
   "metadata": {},
   "source": [
    "- Fisher made 8 cups of tea\n",
    "    - 4 with milk added first\n",
    "    - 4 with tea added in first\n",
    "    \n",
    "- Bristol correctly identified if the tea or millk was poured first for all 8 of the cups\n",
    "\n",
    "\n",
    "### Random sample of 80 STA130 students\n",
    "- suppose:\n",
    "49 students are able to correctly state which was poured first\n",
    "\n",
    "### Data:\n",
    "49/80 students are able to correctly state which was poured first\n",
    "(61.25%)\n",
    "\n",
    "### Statistical Concepts:\n",
    "- Observed data: 49 out of a sample of 80 students were able to correctly state which was poured first(61.3%)\n",
    "- Null hypothesis(Hâ‚€): There's no difference in pouring the tea or milk first(50% of students cannot identify the difference between them)\n",
    "- Sample proportion(pÌ‚): The observed proportion of correctly identifying which one was poured first is 61.3% (0.6125)\n",
    "- Population proportion under Hâ‚€(pâ‚€): The assumed population proportion is 50%(0.5) since we assume no difference\n",
    "- Alternative hypothesis($H_A$): There's diffrence in pouring the tea or milk first, which means $H_0$: $\\mu$ = $\\mu_0$ vs $H_A$: $\\mu$ != $\\mu_0$. \n",
    "- Quantitative Analysis:We have observed that $H_0$ != $H_A$, which is equivalent to 0.5 != 0.6125\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ca6291",
   "metadata": {},
   "source": [
    "# Fisher's Tea Experiment with STA 130 Students\n",
    "## Problem Introduction\n",
    "The original Fisher's Tea Experiemtn aimed to test whether Bristol could correctly identify the order in whcih milk and tea were poured into a cup based on taste. In this modern version of experiment, we replicate the test with 80 STA130 students to determine whether they can accurately state whether the milk or tea was poured first. Out of 80 students, 49 correctly identified the order, yielding a sample proportion of 61.25%. We will now statistically assess whether this result could have occurred by random chance(as assumed by the null hypothesis), or whether there is evidence to reject this assumption.\n",
    "\n",
    "## Relationship to the Original Experiment\n",
    "In the original experiment, Fisher designed a test with eight cups of tea, where Bristol had to correctly identify four cups where milk was poured first and four cups where tea was poured first. She correctly identified all eight cups. The current test differs primarily in sample size, where we are testing 80 students rather than just one person. While the original experiment was focused on the capabilities of a single individual, the STA130 test provides a broader measure of the population's general adbility to detect the difference. \n",
    "\n",
    "# Hypothesis Testing Framework\n",
    "## Observed Data\n",
    "- Sample size(n): 80 students\n",
    "- Observed correct responses(x): 49 students\n",
    "- Observed proportion(pÌ‚): 49/80 = 61.25% = 0.6125\n",
    "\n",
    "## Null Hypothesis($H_0$)\n",
    "The null hypothesis assumes that the students have no genuine ability to distinguish between the order of pouring(milk vs. tea), and that any correct answers are purely due to chance. Thus, under the null hypothesis, the expected proportion of correct responses is 50%:\n",
    "\n",
    "$H_0$ : $p$ = 0.5\n",
    "\n",
    "## Informal Explanation of $H_0$\n",
    "The null hypothesis is saying that, on average, people can't tell whether milk or tea was poured first, so about half of them would guess correctly just by chance.\n",
    "\n",
    "## Alternative Hypothesis($H_A$)\n",
    "The alternative hypothesis states that there is a diffrence in the student's ability to detect the order of pouring, meaning the observed proportion of correct responses is not equal to 50%:\n",
    "\n",
    "$H_A$ : $p$ != 0.5\n",
    "\n",
    "# Quantitative Analysis\n",
    "We will use a hypothesis test to evaluate the null hypothesis. The test compares the observed sample proportion to the hypothesized population proportion(50%) under the null hypothesis, using the sampling distribution of the sample proportion. \n",
    "\n",
    "## 1. Proportion Under the Null Hypothesis($p_0$)\n",
    "Under the null hypothesis, the population proportion($p_0$) is assumed to be 0.5(since there is no expected diffrence between the number of students who can tell the difference and those who can't)\n",
    "\n",
    "## 2. Observed Test Statistic\n",
    "The observed test statistic is the sample proportion(pÌ‚ = 0.6125)\n",
    "\n",
    "$pÌ‚$ = $49/80$  = $0.6125$\n",
    "\n",
    "## 3. Methodology\n",
    "We will calculate the z-statistic to evaluate how far the observed sample proportion(pÌ‚) is from the population proportion under the null hypothesis($p_0 = 0.5$)\n",
    "\n",
    "$z = \\frac{\\hat{p} - p_0}{\\sqrt{\\frac{p_0(1 - p_0)}{n}}}$\n",
    "\n",
    "Where:\n",
    "- pÌ‚ = 0.6125 (observed proportion)\n",
    "- pâ‚€ = 0.5 (null hypothesis proportion)\n",
    "- n = 80 (sample size)\n",
    "\n",
    "The z-statistic gives us a measure of how far the observed sample proportion is from the hypothesized population proportion, in terms of standard errors. \n",
    "\n",
    "## 4. p-value Calculation\n",
    "The p-value is the probability of observing a test statistic as extreme as (or more extreme than) the one obtained, under the assumption that the null hypothesis is true. In a two-sided test, we calculate the probability of observing a value of the sample proportion either greater than or less than the observed proportion, considering both tails of the distribution. \n",
    "\n",
    "For this test, we used the standard normal distribution(since sample size is large enough to apply the Central Limit Theorem) to find the p-value corresponding to the calculated z-statistic.\n",
    "\n",
    "# Interpretation\n",
    "## Expected p-value Comparison\n",
    "- If the p-value is low (commonly less than 0.05), this would provide evidence against the null hypothesis, suggesting that the observed difference in proportions (between 50% and 61.25%) is unlikely to have occurred by chance. We would then reject Hâ‚€ in favour of the alternative hypothesis.\n",
    "\n",
    "- If the p-value is higher (greater than 0.05), this would suggest that the observed result could resonably occur by chance, and we would fail to reject Hâ‚€.\n",
    "\n",
    "Given the observed sample proportion (0.6125), we expect that the test might yield a small p-value, indicating moderate to strong evidence against the null hypothesis. However, the specific p-value will depend on the z-statistic we calculate.\n",
    "\n",
    "# Conclusion\n",
    "If the p-value is small, we will reject the null hypothesis and conclude that there is evidence that some students can correctly detect the order in which milk and tea are poured. If the p-value is large, we will fail to reject the null hypothesis, suggesting that the correct responses could have been due to random guessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec380fa8",
   "metadata": {},
   "source": [
    "# Code for Quantitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f486b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed proportion: 0.6125\n",
      "Z-statistic: 2.0124611797498115\n",
      "P-value: 0.044171344908442434\n",
      "First 5 simulated proportions under Hâ‚€: [0.5    0.525  0.4375 0.4125 0.5875]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set a random seed to make the analysis reproducible\n",
    "np.random.seed(42)  # Choose any integer seed value\n",
    "\n",
    "# Data\n",
    "n = 80  # sample size\n",
    "x = 49  # number of correct responses\n",
    "p_hat = x / n  # sample proportion\n",
    "p_0 = 0.5  # null hypothesis population proportion\n",
    "\n",
    "# Z-statistic calculation\n",
    "z = (p_hat - p_0) / np.sqrt(p_0 * (1 - p_0) / n)\n",
    "\n",
    "# Two-tailed p-value\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "\n",
    "print(f\"Observed proportion: {p_hat}\")\n",
    "print(f\"Z-statistic: {z}\")\n",
    "print(f\"P-value: {p_value}\")\n",
    "\n",
    "# Simulation example (under Hâ‚€)\n",
    "number_of_simulations = 10000\n",
    "simulated_proportions = np.zeros(number_of_simulations)\n",
    "\n",
    "# Simulate the null hypothesis where p = 0.5\n",
    "for i in range(number_of_simulations):\n",
    "    simulated_sample = np.random.binomial(n, p_0) / n\n",
    "    simulated_proportions[i] = simulated_sample\n",
    "\n",
    "# Example of using the seed for reproducibility in random sampling\n",
    "print(f\"First 5 simulated proportions under Hâ‚€: {simulated_proportions[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21f351e",
   "metadata": {},
   "source": [
    "# Conclusion Regarding the Null Hypothesis\n",
    "The statistical analysis, based on the calculated p-value, will inform whether or not we can reject the null hypothesis. A low p-value would suggest strong evidence that the students' ability to detect the order is not due to chance. A high p-value would suggest that their responses could be random guesses. The results of this analysis will be discussed based on the calculated p-value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656e59f",
   "metadata": {},
   "source": [
    "# 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9475da",
   "metadata": {},
   "source": [
    "Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
